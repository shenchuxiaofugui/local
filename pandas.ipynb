{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05f08656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05450ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#从文件夹和信息表中取交集生成新表\n",
    "file_path = r'\\\\mega\\syli\\dataset\\neimo\\eaoc'\n",
    "label_path = r'\\\\mega\\syli\\dataset\\neimo\\label.xlsx'\n",
    "file_df = pd.DataFrame(os.listdir(file_path), columns=['MRI-ID'])\n",
    "label_df = pd.read_excel(label_path)\n",
    "fin_df = pd.merge(file_df, label_df)\n",
    "fin_df.rename(columns={'MRI-ID':'CaseName','MT':'label'},inplace=True)\n",
    "fin_df.to_csv(r'\\\\mega\\syli\\dataset\\neimo\\label1.csv',index=False,encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02304b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#合并label和feature\n",
    "path=r'\\\\mega\\syli\\dataset\\EC_all\\all_frame'\n",
    "df1=pd.read_excel(path+'\\\\fin_df.xlsx')[['ID','淋巴结转移阳性']]   #可设置stp\n",
    "df1['ID'] = df1['ID'].astype(dtype='str')\n",
    "df1.rename(columns={'ID':'CaseName','淋巴结转移阳性':'label'},inplace=True)\n",
    "for modal in ['T1CE', 'DWI', 'T2']:\n",
    "    \n",
    "    df2=pd.read_csv(r'\\\\mega\\syli\\dataset\\EC_all\\yuchuli'+f'\\\\{modal}\\\\{modal}_feature.csv')\n",
    "    df2['CaseName'] = df1['CaseName'].astype(dtype='str')\n",
    "    df5=pd.merge(df1,df2)   #合并数据表,需要共同的列\n",
    "    #df2.insert(1,'label',df3)  #插入列\n",
    "    df5.to_csv(r'\\\\mega\\syli\\dataset\\EC_all\\yuchuli' + f'\\\\{modal}\\\\{modal}.csv',index=False,encoding=\"utf_8_sig\")\n",
    "    #os.mkdir(r'\\\\mega\\syli\\dataset\\endometrial cancer\\data' + f'\\\\{modal}_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fc0f579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5049920']\n"
     ]
    }
   ],
   "source": [
    "a = os.listdir(r'\\\\mega\\MRIData\\Red-House\\EC_all_process_data')\n",
    "b = os.listdir(r'\\\\mega\\syli\\dataset\\EC_all_process_data')\n",
    "print(list(set(b).difference(set(a))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4a1769",
   "metadata": {},
   "source": [
    "# 正则匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb9070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepath=r'\\\\mega\\syli\\dataset\\EC_all\\yuchuli'\n",
    "zong=pd.read_csv(filepath+'\\\\T1_3.csv')\n",
    "feature_list=['log-sigma','wave','original']\n",
    "df3=zong.iloc[:,:2]\n",
    "\n",
    "for feature in feature_list:\n",
    "    os.makedirs(filepath+f\"\\\\{feature}\\\\result\")\n",
    "    df1=zong.filter(regex='^(?!.*?firstorder).*$')   #^不匹配，?!不包含,.*?非贪婪，.*所有内容\n",
    "#df4=zong.filter(regex='firstorder') \n",
    "    df2=df1.filter(regex=f'{feature}')\n",
    "    result_df=pd.merge(df3,df2,left_index=True,right_index=True)\n",
    "    result_df.to_csv(filepath+f'\\\\{feature}\\\\T1_3.csv',index=False)\n",
    "    \n",
    "df4=zong.filter(regex='firstorder')\n",
    "df5=df4.filter(regex='^(?!.*?original).*$')\n",
    "pd.merge(df3,df5,left_index=True,right_index=True).to_csv(filepath+'\\\\bian_firstorder\\\\T1_3.csv',index=False)\n",
    "df5=df4.filter(regex='original')\n",
    "df3=zong.iloc[:,:3]\n",
    "pd.merge(df3,df5,left_index=True,right_index=True).to_csv(filepath+'\\\\ori_firstorder\\\\T1_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cb3bfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#提取建模选好的特征并合并\n",
    "number = 3\n",
    "feature_path=['']*number\n",
    "df_path=['']*number\n",
    "select_df=['']*number\n",
    "feature_path[0]=r'\\\\mega\\syli\\dataset\\endometrial cancer\\data\\+C_result\\Mean\\PCC\\Relief_19\\feature_select_info.csv'\n",
    "df_path[0]=r'\\\\mega\\syli\\dataset\\endometrial cancer\\data\\+C.csv'\n",
    "feature_path[1]=r'\\\\mega\\syli\\dataset\\endometrial cancer\\data\\SAG_result\\Zscore\\PCC\\Relief_8\\feature_select_info.csv'\n",
    "df_path[1]=r'\\\\mega\\syli\\dataset\\endometrial cancer\\data\\SAG.csv'\n",
    "feature_path[2]=r'\\\\mega\\syli\\dataset\\endometrial cancer\\data\\DWI_result\\Zscore\\PCC\\RFE_16\\feature_select_info.csv'\n",
    "df_path[2]=r'\\\\mega\\syli\\dataset\\endometrial cancer\\data\\DWI.csv'\n",
    "# feature_path[3]=r'\\\\mega\\syli\\dataset\\neimo\\data\\T1+_result\\Zscore\\PCC\\KW_15\\feature_select_info.csv'\n",
    "# df_path[3]=r'\\\\mega\\syli\\dataset\\neimo\\data\\T1+.csv'\n",
    "# feature_path[4]=r'\\\\mega\\syli\\dataset\\neimo\\data\\T2_result\\Zscore\\PCC\\Relief_3\\feature_select_info.csv'\n",
    "# df_path[4]=r'\\\\mega\\syli\\dataset\\neimo\\data\\T2.csv' \n",
    "for i in range(number):\n",
    "    print(i)\n",
    "    feature_df=pd.read_csv(feature_path[i])\n",
    "    feature=list(feature_df.index[0])+feature_df.values.flatten().tolist()   #索引行并转换为列表\n",
    "    data_df=pd.read_csv(df_path[i])\n",
    "    feature.pop(0)   #出列\n",
    "    feature.insert(0,'CaseName')  #入栈\n",
    "    feature.insert(1,'label')\n",
    "    select_df[i]=data_df[feature]\n",
    "    if i == 0:\n",
    "        zong_df = select_df[i]\n",
    "    else:\n",
    "        zong_df = pd.merge(zong_df,select_df[i],on=('CaseName','label'))\n",
    "# zong_df=pd.merge(select_df[0],select_df[1],on=('CaseName','label'))  #on可以是两列\n",
    "# zong_df=pd.merge(zong_df,select_df[2],on=('CaseName','label'))\n",
    "zong_df.to_csv(r'\\\\mega\\syli\\dataset\\endometrial cancer\\data\\zong.csv',index=False)\n",
    "#info.rename(columns={'MRI-id':'CaseName'},inplace=True)  #改名"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae3402",
   "metadata": {},
   "source": [
    "# 表格相关操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98238e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#提取表格信息转为列表\n",
    "path=r'D:\\python\\dataset\\GBM-radiomics\\GBM数据增加病例拼音.xlsx'\n",
    "df1=pd.read_excel(path)\n",
    "p53=df1['p53百分比'].values.tolist()\n",
    "p53_label=df1['p53（0=≤50%；1=＞50%）'].values.tolist()\n",
    "MGMT=df1['MGMT（0=≤8%；1=＞8%）'].values.tolist()\n",
    "p53_1=df1['p53_1'].values.tolist()\n",
    "p53_2=df1['p53_2'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3139a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    " \n",
    "def multipl(a,b):\n",
    "    sumofab=0.0\n",
    "    for i in range(len(a)):\n",
    "        temp=a[i]*b[i]\n",
    "        sumofab+=temp\n",
    "    return sumofab\n",
    " \n",
    "def corrcoef(x,y):\n",
    "    n=len(x)\n",
    "    #求和\n",
    "    sum1=sum(x)\n",
    "    sum2=sum(y)\n",
    "    #求乘积之和\n",
    "    sumofxy=multipl(x,y)\n",
    "    #求平方和\n",
    "    sumofx2 = sum([pow(i,2) for i in x])\n",
    "    sumofy2 = sum([pow(j,2) for j in y])\n",
    "    num=sumofxy-(float(sum1)*float(sum2)/n)\n",
    "    #计算皮尔逊相关系数\n",
    "    den=sqrt((sumofx2-float(sum1**2)/n)*(sumofy2-float(sum2**2)/n))\n",
    "    return num/den\n",
    "print(corrcoef(p53_label,MGMT))\n",
    "print(corrcoef(p53_1,MGMT))\n",
    "print(corrcoef(p53_2,MGMT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a5e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#多模态合并计算\n",
    "path=r'\\\\mega\\syli\\dataset\\Primary and metastatic'\n",
    "df1=pd.read_csv(path+'\\\\T1\\\\T1_gai.csv')\n",
    "T1CE_feature=pd.read_csv(path+'\\\\T1CE\\\\T1CE_gai.csv')\n",
    "T2_feature=pd.read_csv(path+'\\\\T2\\\\T2_gai.csv')\n",
    "DWI_feature=pd.read_csv(path+'\\\\DWI\\\\DWI_gai1.csv')\n",
    "df1=pd.merge(df1,T2_feature)\n",
    "df1=pd.merge(df1,T1CE_feature)\n",
    "df1=pd.merge(df1,DWI_feature)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4089b931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算p值\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "d = np.array([[0, 1,1], [0, 1]])\n",
    "tab = pd.crosstab(x, y).fillna(0)\n",
    "chi2_contingency(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#分割特征\n",
    "filepath=r'D:\\python\\dataset\\GBM-radiomics'\n",
    "list1=['CBV','DSC','FLAIR-2','T1-1','T2-1']\n",
    "for file_name in list1:\n",
    "    path=filepath+'\\\\'+file_name+'\\\\firstorder'\n",
    "#     os.mkdir(path+'\\\\ori_result')\n",
    "#     os.mkdir(path+'\\\\bian_result')\n",
    "    for form_path in ['\\\\train_numeric_feature.csv','\\\\test_numeric_feature.csv']:\n",
    "        form=path+form_path\n",
    "        zong=pd.read_csv(form)\n",
    "        df1=zong.filter(regex='^(?!.*?original).*$')   #^不匹配，?!不包含,.*?非贪婪，.*所有内容\n",
    "        df2=zong.filter(regex='original') \n",
    "        df3=zong.iloc[:,:2]\n",
    "        df5=pd.merge(df3,df2,left_index=True,right_index=True)\n",
    "        df1.to_csv(path+'\\\\bian_'+form_path[1:],index=False)\n",
    "        df5.to_csv(path+'\\\\ori_'+form_path[1:],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508af17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df4=df2.filter(regex='^(?!.*?firstorder).*$')   #^不匹配，?!不包含,.*?非贪婪，.*所有内容\n",
    "# df6=df4.filter(regex='wave')  log-sigma-1-0,original\n",
    "#也是分割特征\n",
    "filepath=r'D:\\python\\dataset\\GBM-radiomics\\ki67\\T1-3'\n",
    "zong=pd.read_csv(filepath+'\\\\T1_3.csv')\n",
    "feature_list=['log-sigma-1-0','log-sigma-3-0','log-sigma-5-0','wave','original']\n",
    "df3=zong.iloc[:,:2]\n",
    "\n",
    "for feature in feature_list:\n",
    "    os.mkdir(filepath+f\"\\\\{feature}\")\n",
    "    df1=zong.filter(regex='^(?!.*?firstorder).*$')   #^不匹配，?!不包含,.*?非贪婪，.*所有内容\n",
    "#df4=zong.filter(regex='firstorder') \n",
    "    df2=df1.filter(regex=f'{feature}')\n",
    "    result_df=pd.merge(df3,df2,left_index=True,right_index=True)\n",
    "    result_df.to_csv(filepath+f'\\\\{feature}\\\\T1_3.csv',index=False)\n",
    "    \n",
    "df4=zong.filter(regex='firstorder')\n",
    "df5=df4.filter(regex='^(?!.*?original).*$')\n",
    "pd.merge(df3,df5,left_index=True,right_index=True).to_csv(filepath+'\\\\bian_firstorder\\\\T1_3.csv',index=False)\n",
    "df5=df4.filter(regex='original')\n",
    "df3=zong.iloc[:,:3]\n",
    "pd.merge(df3,df5,left_index=True,right_index=True).to_csv(filepath+'\\\\ori_firstorder\\\\T1_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f86af2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#变换label\n",
    "path = r'\\\\mega\\syli\\dataset\\endometrial cancer'\n",
    "label_df = pd.read_excel(os.path.join(path,'EC分子分型8.61（1）.xlsx'))\n",
    "label_df = label_df[['CaseName', 'label']]\n",
    "i = 0\n",
    "for a in label_df['label']:\n",
    "    if 'P53' in a:\n",
    "        label_df.loc[i, 'label'] = 1\n",
    "    else:\n",
    "        label_df.loc[i, 'label'] = 0\n",
    "    i = i+1\n",
    "label_df.to_csv(r'\\\\mega\\syli\\dataset\\endometrial cancer\\label1.csv',index=False,encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79bae2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#合并label和feature\n",
    "path=r'\\\\mega\\syli\\dataset\\Primary and metastatic\\test\\T1\\T1_feature_4.csv'\n",
    "label_path=r'\\\\mega\\syli\\dataset\\Primary and metastatic\\info.csv'\n",
    "df1=pd.read_csv(path)   #可设置stp\n",
    "df2=pd.read_csv(label_path)[['CaseName','label']]\n",
    "df5=pd.merge(df2,df1)   #合并数据表,需要共同的列\n",
    "#df2.insert(1,'label',df3)  #插入列\n",
    "df5.to_csv(r'\\\\mega\\syli\\dataset\\Primary and metastatic\\test\\T1\\minmax_4\\T1.csv',index=False,encoding=\"utf_8_sig\")\n",
    "#os.mkdir(r'\\\\mega\\syli\\dataset\\endometrial cancer\\data' + f'\\\\{modal}_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d18fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征表提取文件有的\n",
    "key = 'MRID'\n",
    "dirs = os.listdir(r'\\\\mega\\syli\\dataset\\EC_seg\\process_lnm_new\\process_lnm_new')\n",
    "dirs_df = pd.DataFrame(dirs, columns=[key], dtype='str')\n",
    "df = pd.read_excel(r'\\\\mega\\MRIData\\Red-House\\EC_seg\\lnm positive_1.xlsx', sheet_name='合计', dtype='str')\n",
    "fin_df = pd.merge(dirs_df, df, on=key)\n",
    "fin_df.to_csv(r'\\\\mega\\syli\\dataset\\EC_seg\\process_lnm_new\\new_info.csv',index=False,encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f94e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#多个表格提取数据\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "filespath = r'\\\\mega\\syli\\dataset\\EC_all_process_data'\n",
    "files = os.listdir(filespath)\n",
    "files_1 = [x for x in files if 'y' not in x]\n",
    "files_df_1 = pd.DataFrame(files_1, columns=['ID'], dtype='int64')\n",
    "files_df_2 = pd.DataFrame(files, columns=['ID'])\n",
    "#files_df = pd.to_numeric(files_df)\n",
    "df1 = pd.read_excel('//mega\\syli\\dataset/all_frame/biao1.xlsx')\n",
    "df1.rename(columns={'病案号':'ID'}, inplace=True)\n",
    "sum_df = df1[['ID','淋巴结转移阳性','出院日期','发病年龄','身高','体重','病理类型']]\n",
    "df2 = pd.read_excel('//mega\\syli\\dataset/all_frame/biao2.xlsx')\n",
    "df2.rename(columns={'病案号':'ID'}, inplace=True)\n",
    "sum_df = pd.concat([sum_df,df2[['ID','淋巴结转移阳性','出院日期','发病年龄','身高','体重','病理类型']]])\n",
    "df3 = pd.read_excel('//mega\\syli\\dataset/all_frame/biao3.xlsx')\n",
    "df3.rename(columns={'影像号':'ID'}, inplace=True)\n",
    "sum_df = pd.concat([sum_df,df3[['ID','淋巴结转移阳性','出院日期','发病年龄','身高','体重','病理类型']]])\n",
    "df4 = pd.read_excel('//mega\\syli\\dataset/all_frame/biao4.xlsx')[['MRID','淋巴结转移阳性','手术日期','发病年龄','身高','体重','病理类型']]\n",
    "df4.rename(columns={'MRID':'ID','手术日期':'出院日期'}, inplace=True)\n",
    "#df4 = df4[~df4['ID'].isin(['5346549'])]\n",
    "sum_df = pd.concat([sum_df,df4])\n",
    "all_df_1 = pd.merge(files_df_1, sum_df)\n",
    "all_df_2 = pd.merge(files_df_2, sum_df)\n",
    "all_df = pd.concat([all_df_1, all_df_2])\n",
    "#all_df.drop_duplicates(subset=['ID','淋巴结转移阳性','出院日期','发病年龄','身高','体重','病理类型'], keep='first', inplace=True)\n",
    "all_df.to_excel(r'\\\\mega\\syli\\dataset\\all_frame/fin_df_1.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "325f1839",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '\\\\\\\\mega\\\\syli\\\\dataset\\\\all_frame\\\\fin_df.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-7a3a4b2565f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmy_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\\\mega\\syli\\dataset\\all_frame\\fin_df.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mjie_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\handsome\\Documents\\WeChat Files\\wxid_hncq0l75v1pq21\\FileStorage\\File\\2022-03\\lnm_label.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\env\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m                 )\n\u001b[0;32m    298\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\env\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mD:\\env\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1069\u001b[0m                 \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xls\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m                 ext = inspect_excel_format(\n\u001b[0m\u001b[0;32m   1072\u001b[0m                     \u001b[0mcontent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m                 )\n",
      "\u001b[1;32mD:\\env\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(path, content, storage_options)\u001b[0m\n\u001b[0;32m    947\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mcontent_or_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m    950\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m     ) as handle:\n",
      "\u001b[1;32mD:\\env\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '\\\\\\\\mega\\\\syli\\\\dataset\\\\all_frame\\\\fin_df.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "my_df = pd.read_excel(r'\\\\mega\\syli\\dataset\\all_frame\\fin_df_1.xlsx')\n",
    "jie_df = pd.read_csv(r'C:\\Users\\handsome\\Documents\\WeChat Files\\wxid_hncq0l75v1pq21\\FileStorage\\File\\2022-03\\lnm_label.csv')\n",
    "a = my_df['ID'].values.tolist()\n",
    "a = [str(i) for i in a]\n",
    "my_df['ID'] = a\n",
    "b = jie_df['ID'].values.tolist()\n",
    "print(list(set(a).difference(set(b))))\n",
    "print(list(set(b).difference(set(a))))\n",
    "# my_df = my_df.set_index('ID')\n",
    "# jie_df = jie_df.set_index('ID')\n",
    "new_df = pd.merge(my_df, jie_df)\n",
    "for index, row in new_df.iterrows():\n",
    "    if row['label'] != row['淋巴结转移阳性']:\n",
    "        #my_df.loc[index, '淋巴结转移阳性'] = row['label']\n",
    "        print(index, row['label'], row['淋巴结转移阳性'])\n",
    "#my_df.to_excel(r'\\\\mega\\syli\\dataset\\all_frame/fin_df_2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57bd6e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID 脉管内癌栓\n",
      "0  2087438     0\n",
      "1  2119112     0\n",
      "2  4070493     0\n",
      "3  4078034     0\n",
      "4  4078377     1\n",
      "            ID  淋巴结转移阳性        出院日期  发病年龄     身高    体重         病理类型 脉管内癌栓\n",
      "0    y00131065        1  20161106.0  65.0    NaN   NaN       999999   0.0\n",
      "1    y00002416        1  20190122.0  62.0  160.0  83.0            1   1.0\n",
      "2    y00002580        1  20190214.0  61.0  166.0  65.0            1   1.0\n",
      "3    y00004593        1  20190226.0  53.0  147.0  62.0            1   1.0\n",
      "4    y00004585        1  20190304.0  39.0    NaN   NaN            1   1.0\n",
      "..         ...      ...         ...   ...    ...   ...          ...   ...\n",
      "533    5677498        0  20180322.0  50.0  155.0  60.0            1     0\n",
      "534    5671128        0  20180325.0  36.0    NaN   NaN            1     0\n",
      "535    5229971        0         NaN  26.0  160.0  62.0  子宫不典型息肉状腺肌瘤     0\n",
      "536    5229971        0         NaN  26.0  160.0  62.0  子宫不典型息肉状腺肌瘤     0\n",
      "537    5614039        0         NaN  56.0    NaN   NaN            1     1\n",
      "\n",
      "[592 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#给表格额外加数据\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "old_df = pd.read_excel(r'\\\\mega\\syli\\dataset\\EC_all\\all_frame\\fin_df.xlsx')\n",
    "new_df_1 = pd.read_excel(r'\\\\mega\\syli\\dataset\\EC_all\\all_frame\\ori\\biao4.xlsx')[['ID', '脉管内癌栓']]\n",
    "new_df_2 = pd.read_excel(r'\\\\mega\\syli\\dataset\\EC_all\\all_frame\\ori\\biao6.xlsx')[['ID', '脉管内癌栓']]\n",
    "# for index, row in new_df_2.iterrows():\n",
    "#     #new_df_2.loc[index, 'ID'] = row['ID'][1:]\n",
    "#     print(row['ID'])\n",
    "old_df['ID'] = old_df['ID'].astype(dtype='str')\n",
    "new_df_2['ID'] = new_df_2['ID'].astype(dtype='str')\n",
    "print(new_df_2.head())\n",
    "all_df_1 = pd.merge(old_df, new_df_1)\n",
    "all_df_2 = pd.merge(old_df, new_df_2)\n",
    "all_df = pd.concat([all_df_1, all_df_2])\n",
    "print(all_df)\n",
    "\n",
    "#all_df.to_excel(r'\\\\mega\\syli\\dataset\\all_frame/fin_df_1.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#改名\n",
    "import os\n",
    "from pathlib import Path\n",
    "dir_path = r'\\\\mega\\MRIData\\Red-House\\EC_all_process_data'\n",
    "case_list = [i for i in Path(dir_path).iterdir()]\n",
    "for case in case_list:\n",
    "    file_list = [i for i in Path(case).iterdir()]\n",
    "    for file in file_list:\n",
    "        if 'T2_SAG' in file.name:\n",
    "            os.rename(file, str(file).replace('T2_SAG', 'T2'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
